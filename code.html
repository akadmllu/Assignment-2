<!DOCTYPE html><html><head><meta charset="utf-8"><title>Code</title>
<style>pre{font-family:monospace;font-size:11px;}</style></head><body>
<h3>config_kmeans.py</h3><pre>&quot;&quot;&quot;
Configuration for K-Means clustering - ML System Optimization Assignment
&quot;&quot;&quot;

# Dataset
DATASET = &quot;mnist&quot;  # mnist or blobs (synthetic)
DATA_DIR = &quot;./data&quot;
N_SAMPLES = 1500   # Digits has 1797; use subset for faster runs

# K-Means
N_CLUSTERS = 10
MAX_ITERS = 100

# Parallel
N_WORKERS = -1  # -1 = use all CPU cores (for parallel script)
</pre>
<h3>kmeans_baseline.py</h3><pre>&quot;&quot;&quot;
Baseline: Single-process K-Means clustering.
Use for correctness comparison and speedup benchmarking.
&quot;&quot;&quot;

import argparse
import time
import numpy as np
from sklearn.datasets import load_digits, make_blobs
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, adjusted_rand_score

from config_kmeans import (
    DATASET,
    N_SAMPLES,
    N_CLUSTERS,
    MAX_ITERS,
)


def load_data(dataset: str, n_samples: int = None):
    &quot;&quot;&quot;Load dataset for clustering. Returns (X, y) where y is true labels (for ARI).&quot;&quot;&quot;
    if dataset == &quot;mnist&quot;:
        data = load_digits()
        X, y = data.data, data.target
    elif dataset == &quot;blobs&quot;:
        X, y = make_blobs(n_samples=10000, n_features=64, centers=10, random_state=42)
    else:
        raise ValueError(f&quot;Unknown dataset: {dataset}&quot;)

    if n_samples and n_samples &lt; len(X):
        rng = np.random.default_rng(42)
        n_samples = min(n_samples, len(X))
        idx = rng.choice(len(X), n_samples, replace=False)
        X, y = X[idx], y[idx]
    X = StandardScaler().fit_transform(X)
    return X, y


def kmeans_baseline(X: np.ndarray, k: int, max_iters: int, seed: int = 42):
    &quot;&quot;&quot;
    Standard K-Means: single process, sequential assignment and update.
    &quot;&quot;&quot;
    rng = np.random.default_rng(seed)
    n_samples, n_features = X.shape

    # Initialize centroids: k-means++
    centroids = np.zeros((k, n_features))
    centroids[0] = X[rng.integers(n_samples)]
    for i in range(1, k):
        dist_sq = np.min(np.sum((X[:, None] - centroids[:i]) ** 2, axis=2), axis=1)
        probs = dist_sq / dist_sq.sum()
        centroids[i] = X[rng.choice(n_samples, p=probs)]

    for _ in range(max_iters):
        # Assignment: each point -&gt; nearest centroid
        dists = np.sum((X[:, None] - centroids) ** 2, axis=2)
        labels = np.argmin(dists, axis=1)

        # Update: new centroid = mean of assigned points
        new_centroids = np.zeros_like(centroids)
        for j in range(k):
            mask = labels == j
            if mask.sum() &gt; 0:
                new_centroids[j] = X[mask].mean(axis=0)
            else:
                new_centroids[j] = centroids[j]

        if np.allclose(centroids, new_centroids):
            break
        centroids = new_centroids

    return centroids, labels


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(&quot;--dataset&quot;, type=str, default=DATASET)
    parser.add_argument(&quot;--n-samples&quot;, type=int, default=N_SAMPLES)
    parser.add_argument(&quot;--k&quot;, type=int, default=N_CLUSTERS)
    parser.add_argument(&quot;--max-iters&quot;, type=int, default=MAX_ITERS)
    args = parser.parse_args()

    print(&quot;Loading data...&quot;)
    X, y_true = load_data(args.dataset, args.n_samples)
    print(f&quot;Data shape: {X.shape}&quot;)

    print(&quot;\n--- Baseline (Single Process) K-Means ---\n&quot;)
    start = time.perf_counter()
    centroids, labels = kmeans_baseline(X, args.k, args.max_iters)
    elapsed = time.perf_counter() - start

    # Metrics: inertia, silhouette, ARI (when ground truth available)
    inertia = sum(np.sum((X[labels == j] - centroids[j]) ** 2) for j in range(args.k))
    silhouette = silhouette_score(X, labels)
    ari = adjusted_rand_score(y_true, labels) if y_true is not None else None

    print(f&quot;Converged in {len(np.unique(labels))} clusters&quot;)
    print(f&quot;Training time: {elapsed:.2f}s&quot;)
    print(f&quot;Inertia: {inertia:.2f}&quot;)
    print(f&quot;Silhouette score: {silhouette:.4f}&quot;)
    if ari is not None:
        print(f&quot;Adjusted Rand Index: {ari:.4f}&quot;)


if __name__ == &quot;__main__&quot;:
    main()
</pre>
<h3>kmeans_parallel.py</h3><pre>&quot;&quot;&quot;
Parallel K-Means: multiprocessing for assignment step.
Each worker processes a chunk of data points; centroids updated via reduction.
&quot;&quot;&quot;

import argparse
import os
import time
import numpy as np
from joblib import Parallel, delayed
from sklearn.datasets import load_digits, make_blobs
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, adjusted_rand_score

from config_kmeans import (
    DATASET,
    N_SAMPLES,
    N_CLUSTERS,
    MAX_ITERS,
    N_WORKERS,
)


def load_data(dataset: str, n_samples: int = None):
    &quot;&quot;&quot;Load dataset for clustering. Returns (X, y) where y is true labels (for ARI).&quot;&quot;&quot;
    if dataset == &quot;mnist&quot;:
        data = load_digits()
        X, y = data.data, data.target
    elif dataset == &quot;blobs&quot;:
        X, y = make_blobs(n_samples=10000, n_features=64, centers=10, random_state=42)
    else:
        raise ValueError(f&quot;Unknown dataset: {dataset}&quot;)

    if n_samples and n_samples &lt; len(X):
        rng = np.random.default_rng(42)
        n_samples = min(n_samples, len(X))
        idx = rng.choice(len(X), n_samples, replace=False)
        X, y = X[idx], y[idx]
    X = StandardScaler().fit_transform(X)
    return X, y


def _assign_chunk(X_chunk: np.ndarray, centroids: np.ndarray):
    &quot;&quot;&quot;
    Worker: assign chunk of points to nearest centroid.
    Returns (labels_chunk, sum_per_cluster, count_per_cluster).
    &quot;&quot;&quot;
    k = centroids.shape[0]
    dists = np.sum((X_chunk[:, None] - centroids) ** 2, axis=2)
    labels = np.argmin(dists, axis=1)

    sums = np.zeros_like(centroids)
    counts = np.zeros(k, dtype=np.int64)
    for j in range(k):
        mask = labels == j
        counts[j] = mask.sum()
        if counts[j] &gt; 0:
            sums[j] = X_chunk[mask].sum(axis=0)
    return sums, counts


def kmeans_parallel(
    X: np.ndarray,
    k: int,
    max_iters: int,
    n_workers: int = -1,
    seed: int = 42,
):
    &quot;&quot;&quot;
    Parallel K-Means: assignment step distributed across workers via joblib.
    &quot;&quot;&quot;
    rng = np.random.default_rng(seed)
    n_samples, n_features = X.shape

    # Initialize centroids: k-means++
    centroids = np.zeros((k, n_features))
    centroids[0] = X[rng.integers(n_samples)]
    for i in range(1, k):
        dist_sq = np.min(np.sum((X[:, None] - centroids[:i]) ** 2, axis=2), axis=1)
        probs = dist_sq / dist_sq.sum()
        centroids[i] = X[rng.choice(n_samples, p=probs)]

    n_chunks = os.cpu_count() if n_workers == -1 else n_workers
    n_chunks = max(1, min(n_chunks, n_samples))

    for _ in range(max_iters):
        chunks = np.array_split(X, n_chunks)
        results = Parallel(n_jobs=n_workers)(
            delayed(_assign_chunk)(chunk, centroids) for chunk in chunks
        )

        # Aggregate: sum and count per cluster
        total_sums = np.zeros_like(centroids)
        total_counts = np.zeros(k, dtype=np.int64)
        for sums, counts in results:
            total_sums += sums
            total_counts += counts

        # Update centroids
        new_centroids = np.zeros_like(centroids)
        for j in range(k):
            if total_counts[j] &gt; 0:
                new_centroids[j] = total_sums[j] / total_counts[j]
            else:
                new_centroids[j] = centroids[j]

        if np.allclose(centroids, new_centroids):
            break
        centroids = new_centroids

    # Final assignment (single pass or parallel) for labels
    dists = np.sum((X[:, None] - centroids) ** 2, axis=2)
    labels = np.argmin(dists, axis=1)
    return centroids, labels


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(&quot;--dataset&quot;, type=str, default=DATASET)
    parser.add_argument(&quot;--n-samples&quot;, type=int, default=N_SAMPLES)
    parser.add_argument(&quot;--k&quot;, type=int, default=N_CLUSTERS)
    parser.add_argument(&quot;--max-iters&quot;, type=int, default=MAX_ITERS)
    parser.add_argument(&quot;--n-workers&quot;, type=int, default=N_WORKERS)
    args = parser.parse_args()

    print(&quot;Loading data...&quot;)
    X, y_true = load_data(args.dataset, args.n_samples)
    print(f&quot;Data shape: {X.shape}&quot;)

    n_workers = args.n_workers if args.n_workers &gt; 0 else -1
    print(f&quot;\n--- Parallel K-Means ({n_workers} workers) ---\n&quot;)
    start = time.perf_counter()
    centroids, labels = kmeans_parallel(
        X, args.k, args.max_iters, n_workers=n_workers
    )
    elapsed = time.perf_counter() - start

    inertia = sum(np.sum((X[labels == j] - centroids[j]) ** 2) for j in range(args.k))
    silhouette = silhouette_score(X, labels)
    ari = adjusted_rand_score(y_true, labels) if y_true is not None else None

    print(f&quot;Converged in {len(np.unique(labels))} clusters&quot;)
    print(f&quot;Training time: {elapsed:.2f}s&quot;)
    print(f&quot;Inertia: {inertia:.2f}&quot;)
    print(f&quot;Silhouette score: {silhouette:.4f}&quot;)
    if ari is not None:
        print(f&quot;Adjusted Rand Index: {ari:.4f}&quot;)


if __name__ == &quot;__main__&quot;:
    main()
</pre>
<h3>run_benchmark_kmeans.py</h3><pre>&quot;&quot;&quot;
Run baseline and parallel K-Means for benchmarking.
Captures: time, inertia, silhouette score, ARI, speedup.
Outputs results for report and PDF generation.
&quot;&quot;&quot;

import json
import os
import sys
import time

# Add project root for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import numpy as np
from sklearn.metrics import silhouette_score, adjusted_rand_score

from kmeans_baseline import kmeans_baseline, load_data
from kmeans_parallel import kmeans_parallel


def run_benchmark(n_samples=10000, k=10, max_iters=50, dataset=&quot;mnist&quot;, n_workers=-1):
    &quot;&quot;&quot;Run both baseline and parallel, return metrics dict.&quot;&quot;&quot;
    print(&quot;Loading data...&quot;)
    X, y_true = load_data(dataset, n_samples)
    print(f&quot;Data shape: {X.shape}, Dataset: {dataset}\n&quot;)

    results = {&quot;dataset&quot;: dataset, &quot;n_samples&quot;: n_samples, &quot;k&quot;: k, &quot;max_iters&quot;: max_iters}

    # Baseline
    print(&quot;--- Baseline (Single Process) ---&quot;)
    start = time.perf_counter()
    centroids_b, labels_b = kmeans_baseline(X, k, max_iters)
    t_baseline = time.perf_counter() - start

    inertia_b = sum(np.sum((X[labels_b == j] - centroids_b[j]) ** 2) for j in range(k))
    sil_b = silhouette_score(X, labels_b)
    ari_b = adjusted_rand_score(y_true, labels_b)

    results[&quot;baseline&quot;] = {
        &quot;time_s&quot;: round(t_baseline, 2),
        &quot;inertia&quot;: round(float(inertia_b), 2),
        &quot;silhouette&quot;: round(float(sil_b), 4),
        &quot;ari&quot;: round(float(ari_b), 4),
    }
    print(f&quot;Time: {t_baseline:.2f}s | Inertia: {inertia_b:.2f} | Silhouette: {sil_b:.4f} | ARI: {ari_b:.4f}\n&quot;)

    # Parallel
    n_w = n_workers if n_workers &gt; 0 else os.cpu_count()
    print(f&quot;--- Parallel ({n_w} workers) ---&quot;)
    start = time.perf_counter()
    centroids_p, labels_p = kmeans_parallel(X, k, max_iters, n_workers=n_workers)
    t_parallel = time.perf_counter() - start

    inertia_p = sum(np.sum((X[labels_p == j] - centroids_p[j]) ** 2) for j in range(k))
    sil_p = silhouette_score(X, labels_p)
    ari_p = adjusted_rand_score(y_true, labels_p)

    results[&quot;parallel&quot;] = {
        &quot;time_s&quot;: round(t_parallel, 2),
        &quot;inertia&quot;: round(float(inertia_p), 2),
        &quot;silhouette&quot;: round(float(sil_p), 4),
        &quot;ari&quot;: round(float(ari_p), 4),
    }
    results[&quot;speedup&quot;] = round(t_baseline / t_parallel, 2) if t_parallel &gt; 0 else 0

    print(f&quot;Time: {t_parallel:.2f}s | Inertia: {inertia_p:.2f} | Silhouette: {sil_p:.4f} | ARI: {ari_p:.4f}\n&quot;)

    print(&quot;=&quot; * 60)
    print(&quot;BENCHMARK SUMMARY&quot;)
    print(&quot;=&quot; * 60)
    print(f&quot;Baseline time: {t_baseline:.2f}s&quot;)
    print(f&quot;Parallel time: {t_parallel:.2f}s&quot;)
    print(f&quot;Speedup: {results[&#x27;speedup&#x27;]:.2f}x&quot;)
    print(f&quot;Correctness: Inertia diff={abs(inertia_b-inertia_p):.2f}, ARI diff={abs(ari_b-ari_p):.4f}&quot;)

    return results


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument(&quot;--n-samples&quot;, type=int, default=10000)
    parser.add_argument(&quot;--k&quot;, type=int, default=10)
    parser.add_argument(&quot;--max-iters&quot;, type=int, default=50)
    parser.add_argument(&quot;--dataset&quot;, type=str, default=&quot;mnist&quot;)
    parser.add_argument(&quot;--n-workers&quot;, type=int, default=-1)
    parser.add_argument(&quot;--output&quot;, type=str, default=&quot;benchmark_results.json&quot;)
    args = parser.parse_args()

    results = run_benchmark(
        n_samples=args.n_samples,
        k=args.k,
        max_iters=args.max_iters,
        dataset=args.dataset,
        n_workers=args.n_workers,
    )
    with open(args.output, &quot;w&quot;) as f:
        json.dump(results, f, indent=2)
    print(f&quot;\nResults saved to {args.output}&quot;)


if __name__ == &quot;__main__&quot;:
    main()
</pre>
<h3>generate_pdfs.py</h3><pre>&quot;&quot;&quot;
Generate assignment deliverables: code.pdf, report.pdf (or .html fallback).
Run after: python run_benchmark_kmeans.py --output benchmark_results.json

If reportlab fails to install (e.g. Pillow build issues), generates HTML instead.
Open report.html/code.html in browser and use Print -&gt; Save as PDF.
&quot;&quot;&quot;

import html
import json
import os
import sys
from pathlib import Path

# Try reportlab; fall back to HTML if unavailable
USE_REPORTLAB = False
try:
    from reportlab.lib.pagesizes import letter
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Preformatted, Spacer, Table, TableStyle
    from reportlab.lib import colors
    USE_REPORTLAB = True
except ImportError:
    pass


# Code files to include in code.pdf (K-means assignment)
CODE_FILES = [
    &quot;config_kmeans.py&quot;,
    &quot;kmeans_baseline.py&quot;,
    &quot;kmeans_parallel.py&quot;,
    &quot;run_benchmark_kmeans.py&quot;,
    &quot;generate_pdfs.py&quot;,
]

# Team contribution table (corresponding author first, will be bold in PDF)
TEAM_CONTRIBUTION = [
    (&quot;DEBASHIS KUMAR SERAOGI&quot;, &quot;2024ad05321&quot;, &quot;Reviewed the paper and Drafted the Problem statement and solution&quot;),
    (&quot;BANDI DEEPIKA&quot;, &quot;2024ad05231&quot;, &quot;Contributed in reviewing the paper and in drafting the Problem statement and solution&quot;),
    (&quot;DURGARAJU SIVA SAKET&quot;, &quot;2024ad05485&quot;, &quot;Contributed in reviewing the paper and in drafting the Problem statement and solution&quot;),
    (&quot;GOKUL PRASANTH A .&quot;, &quot;2024ad05345&quot;, &quot;Contributed in reviewing the paper and in drafting the Problem statement and solution&quot;),
    (&quot;KADMLLU AMIT SUNIL .&quot;, &quot;2024ad05153&quot;, &quot;Contributed in reviewing the paper and in drafting the Problem statement and solution&quot;),
]


def generate_code_pdf(output_path=&quot;code.pdf&quot;):
    &quot;&quot;&quot;Create PDF or HTML of source code.&quot;&quot;&quot;
    base = Path(__file__).parent
    if USE_REPORTLAB:
        doc = SimpleDocTemplate(output_path, pagesize=letter, topMargin=0.5*inch, bottomMargin=0.5*inch)
        styles = getSampleStyleSheet()
        story = []
        code_style = ParagraphStyle(name=&quot;Code&quot;, fontName=&quot;Courier&quot;, fontSize=8, leading=10)
        for filename in CODE_FILES:
            filepath = base / filename
            if not filepath.exists():
                continue
            story.append(Paragraph(f&quot;&lt;b&gt;--- {filename} ---&lt;/b&gt;&quot;, styles[&quot;Normal&quot;]))
            story.append(Spacer(1, 6))
            with open(filepath, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:
                code = f.read()
            story.append(Preformatted(code, code_style))
            story.append(Spacer(1, 12))
        doc.build(story)
    else:
        out = output_path.replace(&quot;.pdf&quot;, &quot;.html&quot;)
        parts = [&#x27;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;Code&lt;/title&gt;&#x27;]
        parts.append(&#x27;&lt;style&gt;pre{font-family:monospace;font-size:11px;}&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&#x27;)
        for filename in CODE_FILES:
            filepath = base / filename
            if not filepath.exists():
                continue
            with open(filepath, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:
                code = html.escape(f.read())
            parts.append(f&#x27;&lt;h3&gt;{html.escape(filename)}&lt;/h3&gt;&lt;pre&gt;{code}&lt;/pre&gt;&#x27;)
        parts.append(&#x27;&lt;/body&gt;&lt;/html&gt;&#x27;)
        with open(out, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:
            f.write(&quot;\n&quot;.join(parts))
        print(f&quot;Generated: {out} (open in browser, Print -&gt; Save as PDF)&quot;)
        return
    print(f&quot;Generated: {output_path}&quot;)


def _write_report_html(out_path, sections_text, results=None, github_url=&quot;&quot;):
    &quot;&quot;&quot;Write report as HTML when reportlab unavailable.&quot;&quot;&quot;
    html_parts = [
        &#x27;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;Report&lt;/title&gt;&#x27;,
        &#x27;&lt;style&gt;body{font-family:sans-serif;max-width:700px;margin:40px auto;line-height:1.5;}&#x27;
        &#x27;h1,h2{color:#333;} table{border-collapse:collapse;} th,td{border:1px solid #ccc;padding:8px;}&lt;/style&gt;&#x27;,
        &#x27;&lt;/head&gt;&lt;body&gt;&#x27;
    ]
    for title, body in sections_text:
        html_parts.append(f&#x27;&lt;h2&gt;{html.escape(title)}&lt;/h2&gt;&#x27;)
        if title == &quot;Facing Sheet&quot;:
            gh = github_url or &quot;[INSERT LINK - to be included in facing sheet]&quot;
            html_parts.append(&#x27;&lt;p&gt;&lt;b&gt;GitHub (link to code):&lt;/b&gt; &#x27; + html.escape(gh) + &#x27;&lt;/p&gt;&#x27;)
            html_parts.append(&#x27;&lt;p&gt;&lt;b&gt;Team Contribution (corresponding author in bold):&lt;/b&gt;&lt;/p&gt;&#x27;)
            html_parts.append(&#x27;&lt;table&gt;&lt;tr&gt;&lt;th&gt;Name&lt;/th&gt;&lt;th&gt;Roll Number&lt;/th&gt;&lt;th&gt;Contribution&lt;/th&gt;&lt;/tr&gt;&#x27;)
            for i, (name, roll, contrib) in enumerate(TEAM_CONTRIBUTION):
                name_cell = f&#x27;&lt;b&gt;{html.escape(name)}&lt;/b&gt;&#x27; if i == 0 else html.escape(name)
                html_parts.append(f&#x27;&lt;tr&gt;&lt;td&gt;{name_cell}&lt;/td&gt;&lt;td&gt;{html.escape(roll)}&lt;/td&gt;&lt;td&gt;{html.escape(contrib)}&lt;/td&gt;&lt;/tr&gt;&#x27;)
            html_parts.append(&#x27;&lt;/table&gt;&lt;p&gt;&lt;i&gt;Corresponding author in bold.&lt;/i&gt;&lt;/p&gt;&#x27;)
        else:
            for p in body.split(&quot;\n\n&quot;):
                html_parts.append(f&#x27;&lt;p&gt;{html.escape(p).replace(chr(10), &quot;&lt;br/&gt;&quot;)}&lt;/p&gt;&#x27;)
    if results:
        html_parts.append(&#x27;&lt;h2&gt;Benchmark Results&lt;/h2&gt;&lt;table&gt;&#x27;)
        for row in [[&quot;Metric&quot;, &quot;Baseline&quot;, &quot;Parallel&quot;], [&quot;Time (s)&quot;, results.get(&quot;baseline&quot;, {}).get(&quot;time_s&quot;), results.get(&quot;parallel&quot;, {}).get(&quot;time_s&quot;)]]:
            html_parts.append(f&#x27;&lt;tr&gt;&lt;td&gt;{row[0]}&lt;/td&gt;&lt;td&gt;{row[1]}&lt;/td&gt;&lt;td&gt;{row[2]}&lt;/td&gt;&lt;/tr&gt;&#x27;)
        html_parts.append(f&#x27;&lt;tr&gt;&lt;td&gt;Speedup&lt;/td&gt;&lt;td colspan=&quot;2&quot;&gt;{results.get(&quot;speedup&quot;)}x&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&#x27;)
    html_parts.append(&#x27;&lt;/body&gt;&lt;/html&gt;&#x27;)
    with open(out_path, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:
        f.write(&quot;\n&quot;.join(html_parts))
    print(f&quot;Generated: {out_path} (open in browser, Print -&gt; Save as PDF)&quot;)


def generate_report_pdf(output_path=&quot;report.pdf&quot;, results_path=&quot;benchmark_results.json&quot;, github_url=&quot;&quot;):
    &quot;&quot;&quot;Create report PDF or HTML with P0-P3 structure and benchmark results.&quot;&quot;&quot;
    results = None
    if os.path.exists(results_path):
        with open(results_path) as f:
            results = json.load(f)

    sections = []

    def add_section(title, body):
        sections.append((title, body))

    add_section(&quot;ML System Optimization - Assignment 2&quot;, &quot;Parallel K-Means Clustering&quot;)
    github_text = github_url if github_url else &quot;[INSERT LINK - to be included in facing sheet]&quot;
    add_section(&quot;Facing Sheet&quot;,
        f&quot;GitHub: {github_text}\n\n&quot;
        &quot;Team Contribution (corresponding author in bold):\n&quot;
        &quot;Name | Roll Number | Contribution&quot;)
    add_section(&quot;Introduction&quot;,
        &quot;This assignment addresses ML System Optimization through parallelization of the K-Means clustering algorithm. &quot;
        &quot;We implement and compare a baseline (single-process) and a parallel (multi-process) version.&quot;)
    add_section(&quot;Literature Survey&quot;,
        &quot;K-Means clustering [MacQueen, 1967]. Parallelization: data parallelism (Spark MLlib, Dask-ML). &quot;
        &quot;k-means++ [Arthur &amp; Vassilvitskii, 2007]. Joblib for single-machine parallelism.&quot;)
    add_section(&quot;Abstract&quot;,
        &quot;Data-parallel K-Means using Python and joblib. Compare baseline vs parallel on Digits dataset. &quot;
        &quot;Metrics: training time, inertia, silhouette score, Adjusted Rand Index.&quot;)
    add_section(&quot;P0: Problem Formulation&quot;,
        &quot;Algorithm: K-Means. Parallelization: data parallelism over assignment step. &quot;
        &quot;Expectations: Speedup ~linear with CPU cores; Communication O(k*d); Reduced response time.&quot;)
    add_section(&quot;P1: Design&quot;,
        &quot;Architecture: Single-machine, multi-process with joblib. Chunk-based split, parallel assignment, k-means++ init.&quot;)
    add_section(&quot;P1 (Revised): Implementation Details&quot;,
        &quot;Environment: Python 3.10+, CPU multi-core. Libraries: NumPy, scikit-learn, joblib.&quot;)
    add_section(&quot;P2: Implementation&quot;,
        &quot;Files: kmeans_baseline.py, kmeans_parallel.py, run_benchmark_kmeans.py.&quot;)
    if results:
        b, p = results.get(&quot;baseline&quot;, {}), results.get(&quot;parallel&quot;, {})
        spd = results.get(&quot;speedup&quot;, 0)
        add_section(&quot;P3: Results and Discussion&quot;,
            f&quot;Dataset: {results.get(&#x27;dataset&#x27;)}, n={results.get(&#x27;n_samples&#x27;)}. &quot;
            f&quot;Baseline: Time={b.get(&#x27;time_s&#x27;)}s, Inertia={b.get(&#x27;inertia&#x27;)}, Silhouette={b.get(&#x27;silhouette&#x27;)}, ARI={b.get(&#x27;ari&#x27;)}. &quot;
            f&quot;Parallel: Time={p.get(&#x27;time_s&#x27;)}s. Speedup: {spd}x. Correctness: inertia and ARI comparable.&quot;)
        add_section(&quot;Deviation from Expectations&quot;,
            f&quot;If speedup ({spd}x) is below expected (e.g. ~linear with cores): possible causesâ€”overhead from process spawning, &quot;
            &quot;small dataset size, or I/O bottlenecks. If clustering quality (ARI) differs between baseline and parallel: &quot;
            &quot;k-means is stochastic; small differences are normal due to floating-point order. &quot;
            &quot;Fill in specific reasons if your results deviated significantly.&quot;)
    else:
        add_section(&quot;P3: Results and Discussion&quot;, &quot;Run run_benchmark_kmeans.py then re-run this script.&quot;)
        add_section(&quot;Deviation from Expectations&quot;, &quot;After running benchmark, add reasons if results deviated from expectations.&quot;)
    add_section(&quot;Conclusion&quot;, &quot;Successfully parallelized K-Means using joblib with measurable speedup.&quot;)
    add_section(&quot;References&quot;,
        &quot;[1] MacQueen (1967). [2] Arthur &amp; Vassilvitskii (2007) k-means++. [3] scikit-learn, joblib docs.&quot;)

    if not USE_REPORTLAB:
        _write_report_html(output_path.replace(&quot;.pdf&quot;, &quot;.html&quot;), sections, results, github_url)
        return

    def add_page_footer(canv, _doc):
        &quot;&quot;&quot;Draw &#x27;-- N --&#x27; at bottom center (like Assignment-1 PDF).&quot;&quot;&quot;
        page_num = canv.getPageNumber()
        canv.saveState()
        canv.setFont(&quot;Helvetica&quot;, 9)
        canv.drawCentredString(letter[0] / 2, 0.5 * inch, f&quot;-- {page_num} --&quot;)
        canv.restoreState()

    doc = SimpleDocTemplate(
        output_path,
        pagesize=letter,
        topMargin=0.75 * inch,
        bottomMargin=0.75 * inch,
        onFirstPage=add_page_footer,
        onLaterPages=add_page_footer,
    )
    styles = getSampleStyleSheet()
    story = []

    def section(title, body):
        story.append(Paragraph(f&quot;&lt;b&gt;{title}&lt;/b&gt;&quot;, styles[&quot;Heading2&quot;]))
        for para in body.split(&quot;\n\n&quot;):
            story.append(Paragraph(para.replace(&quot;\n&quot;, &quot;&lt;br/&gt;&quot;), styles[&quot;Normal&quot;]))
        story.append(Spacer(1, 12))

    # Page 1: Title block (like Assignment-1)
    story.append(Paragraph(
        &quot;&lt;b&gt;ML System Optimization - Assignment 2&lt;/b&gt;&quot;,
        ParagraphStyle(name=&quot;ReportTitle&quot;, fontName=&quot;Helvetica-Bold&quot;, fontSize=14, spaceAfter=6),
    ))
    story.append(Paragraph(
        &quot;Parallel K-Means Clustering&quot;,
        ParagraphStyle(name=&quot;Subtitle&quot;, fontName=&quot;Helvetica&quot;, fontSize=12, spaceAfter=4),
    ))
    story.append(Paragraph(
        &quot;[P0] Problem Formulation, [P1] Design, [P2] Implementation, [P3] Results&quot;,
        ParagraphStyle(name=&quot;Parts&quot;, fontName=&quot;Helvetica&quot;, fontSize=10, spaceAfter=16),
    ))
    # Facing sheet: GitHub + team table
    gh_text = github_url if github_url else &quot;[INSERT LINK - to be included in facing sheet]&quot;
    story.append(Paragraph(f&quot;&lt;b&gt;GitHub (link to code):&lt;/b&gt; {gh_text}&quot;, styles[&quot;Normal&quot;]))
    story.append(Spacer(1, 8))
    story.append(Paragraph(&quot;&lt;b&gt;Team Contribution (corresponding author in bold):&lt;/b&gt;&quot;, styles[&quot;Normal&quot;]))
    # Table: header + 5 members (first name in bold)
    table_data = [[&quot;Name&quot;, &quot;Roll Number&quot;, &quot;Contribution&quot;]]
    small_style = ParagraphStyle(name=&quot;Small&quot;, fontName=&quot;Helvetica&quot;, fontSize=9)
    for i, (name, roll, contrib) in enumerate(TEAM_CONTRIBUTION):
        name_cell = Paragraph(f&quot;&lt;b&gt;{name}&lt;/b&gt;&quot;, small_style) if i == 0 else Paragraph(name, small_style)
        table_data.append([name_cell, roll, Paragraph(contrib.replace(&quot;\n&quot;, &quot;&lt;br/&gt;&quot;), small_style)])
    tbl = Table(table_data, colWidths=[1.8 * inch, 1.1 * inch, 3.1 * inch])
    tbl.setStyle(TableStyle([
        (&quot;BACKGROUND&quot;, (0, 0), (-1, 0), colors.lightgrey),
        (&quot;GRID&quot;, (0, 0), (-1, -1), 0.5, colors.black),
        (&quot;VALIGN&quot;, (0, 0), (-1, -1), &quot;TOP&quot;),
    ]))
    story.append(tbl)
    story.append(Spacer(1, 16))

    # Introduction
    section(
        &quot;Introduction&quot;,
        &quot;This assignment addresses ML System Optimization through parallelization of the K-Means clustering algorithm. &quot;
        &quot;We implement and compare a baseline (single-process) and a parallel (multi-process) version, &quot;
        &quot;demonstrating correctness and performance improvement on CPU-based execution.&quot;
    )

    # Literature Survey
    section(
        &quot;Literature Survey&quot;,
        &quot;K-Means clustering [MacQueen, 1967] is a widely used unsupervised algorithm. &quot;
        &quot;Parallelization strategies include data parallelism (splitting points across workers), &quot;
        &quot;as in Spark MLlib and Dask-ML; and model parallelism for streaming variants. &quot;
        &quot;k-means++ [Arthur &amp; Vassilvitskii, 2007] improves initialization. &quot;
        &quot;Joblib and multiprocessing enable single-machine parallelism in Python.&quot;
    )

    # Abstract
    section(
        &quot;Abstract&quot;,
        &quot;This report presents the parallelization of K-Means clustering for ML System Optimization. &quot;
        &quot;We implement data-parallel K-Means using Python and joblib, distributing the assignment step &quot;
        &quot;across CPU cores. We compare baseline (single-process) and parallel implementations on the &quot;
        &quot;Digits dataset, measuring training time, inertia, silhouette score, and Adjusted Rand Index.&quot;
    )

    # P0
    section(
        &quot;P0: Problem Formulation&quot;,
        &quot;Algorithm: K-Means clustering. Parallelization: Data parallelism over the assignment step. &quot;
        &quot;Each worker processes a chunk of data points. Expectations: Speedup ~linear with CPU cores; &quot;
        &quot;Communication cost O(k*d) per iteration; Reduced response time.&quot;
    )

    # P1
    section(
        &quot;P1: Design&quot;,
        &quot;Architecture: Single-machine, multi-process parallelism using joblib. &quot;
        &quot;Key choices: chunk-based data split, parallel assignment, sequential centroid update, k-means++ init.&quot;
    )

    # P1 Revised
    section(
        &quot;P1 (Revised): Implementation Details&quot;,
        &quot;Environment: Python 3.10+, CPU multi-core. Libraries: NumPy, scikit-learn, joblib.&quot;
    )

    # P2
    section(
        &quot;P2: Implementation&quot;,
        &quot;Files: kmeans_baseline.py, kmeans_parallel.py, run_benchmark_kmeans.py. &quot;
        &quot;Run: python kmeans_baseline.py | python kmeans_parallel.py | python run_benchmark_kmeans.py&quot;
    )

    # P3
    if results:
        b = results.get(&quot;baseline&quot;, {})
        p = results.get(&quot;parallel&quot;, {})
        speedup = results.get(&quot;speedup&quot;, 0)
        section(
            &quot;P3: Results and Discussion&quot;,
            f&quot;Dataset: {results.get(&#x27;dataset&#x27;)}, n={results.get(&#x27;n_samples&#x27;)}, k={results.get(&#x27;k&#x27;)}. &quot;
            f&quot;Baseline: Time={b.get(&#x27;time_s&#x27;)}s, Inertia={b.get(&#x27;inertia&#x27;)}, Silhouette={b.get(&#x27;silhouette&#x27;)}, ARI={b.get(&#x27;ari&#x27;)}. &quot;
            f&quot;Parallel: Time={p.get(&#x27;time_s&#x27;)}s, Inertia={p.get(&#x27;inertia&#x27;)}, Silhouette={p.get(&#x27;silhouette&#x27;)}, ARI={p.get(&#x27;ari&#x27;)}. &quot;
            f&quot;Speedup: {speedup}x. Correctness: inertia and ARI comparable between baseline and parallel.&quot;
        )
        section(
            &quot;Deviation from Expectations&quot;,
            &quot;If speedup is below expected (e.g. near-linear with CPU cores): possible causes include overhead from &quot;
            &quot;process spawning, small dataset size, or I/O bottlenecks. If clustering quality (ARI/silhouette) differs: &quot;
            &quot;k-means is stochastic; small differences are normal. Fill in specific reasons if your results deviated &quot;
            &quot;significantly from expectations.&quot;
        )
    else:
        section(&quot;P3: Results and Discussion&quot;, &quot;Run &#x27;python run_benchmark_kmeans.py&#x27; then re-run this script.&quot;)
        section(&quot;Deviation from Expectations&quot;, &quot;After running benchmark, add reasons if results deviated from expectations.&quot;)

    # Conclusion
    section(
        &quot;Conclusion&quot;,
        &quot;We successfully parallelized K-Means using joblib, achieving measurable speedup on multi-core CPUs.&quot;
    )

    # References
    story.append(Paragraph(&quot;&lt;b&gt;References&lt;/b&gt;&quot;, styles[&quot;Heading2&quot;]))
    for r in [
        &quot;[1] MacQueen, J. (1967). Some methods for classification and analysis of multivariate observations.&quot;,
        &quot;[2] Arthur, D. &amp; Vassilvitskii, S. (2007). k-means++: The Advantages of Careful Seeding.&quot;,
        &quot;[3] scikit-learn KMeans, joblib Parallel documentation.&quot;,
    ]:
        story.append(Paragraph(r, styles[&quot;Normal&quot;]))

    doc.build(story)
    print(f&quot;Generated: {output_path}&quot;)


def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument(&quot;--code&quot;, action=&quot;store_true&quot;, help=&quot;Generate code.pdf&quot;)
    parser.add_argument(&quot;--report&quot;, action=&quot;store_true&quot;, help=&quot;Generate report.pdf&quot;)
    parser.add_argument(&quot;--all&quot;, action=&quot;store_true&quot;, help=&quot;Generate both (default)&quot;)
    parser.add_argument(&quot;--results&quot;, type=str, default=&quot;benchmark_results.json&quot;)
    parser.add_argument(&quot;--github&quot;, type=str, default=&quot;&quot;, help=&quot;GitHub URL for code (facing sheet)&quot;)
    args = parser.parse_args()

    if args.all or (not args.code and not args.report):
        generate_code_pdf()
        generate_report_pdf(results_path=args.results, github_url=args.github)
    else:
        if args.code:
            generate_code_pdf()
        if args.report:
            generate_report_pdf(results_path=args.results, github_url=args.github)


if __name__ == &quot;__main__&quot;:
    main()
</pre>
</body></html>